{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a851d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type:   <torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal object at 0x000002BFE7DE5430>\n",
      "Number of samples sequences:  34249\n",
      "Number of train buckets:  30824\n",
      "Number of test buckets:  3425\n",
      "Type of train_dataset [<torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal object at 0x000002BF995F89D0>]\n",
      "TemporalGNN(\n",
      "  (sttn): STTN(\n",
      "    (embed): Embedding(\n",
      "      (conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (st_blocks): ModuleList(\n",
      "      (0-4): 5 x STBlock(\n",
      "        (STN): SpatialTransformer(\n",
      "          (conv): Conv2d(283, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gcn): GCN(\n",
      "            (conv1): GCNLayer(\n",
      "              (W): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "            (conv2): GCNLayer(\n",
      "              (W): Linear(in_features=256, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (atten): MultiHeadAttention(\n",
      "            (W_Q): Linear(in_features=64, out_features=256, bias=False)\n",
      "            (W_K): Linear(in_features=64, out_features=256, bias=False)\n",
      "            (W_V): Linear(in_features=64, out_features=256, bias=False)\n",
      "            (fc): Linear(in_features=256, out_features=64, bias=False)\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (feed_forward): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          )\n",
      "          (fs): Linear(in_features=64, out_features=1, bias=True)\n",
      "          (fg): Linear(in_features=64, out_features=1, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (TTN): TemporalTransformer(\n",
      "          (conv): Conv2d(76, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (atten): MultiHeadAttention(\n",
      "            (W_Q): Linear(in_features=64, out_features=256, bias=False)\n",
      "            (W_K): Linear(in_features=64, out_features=256, bias=False)\n",
      "            (W_V): Linear(in_features=64, out_features=256, bias=False)\n",
      "            (fc): Linear(in_features=256, out_features=64, bias=False)\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (feed_forward): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (pred): Pred(\n",
      "      (conv1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (conv2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Dataset type:   <torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal object at 0x000002BF8265EC70>\n",
      "Number of samples sequences:  34249\n",
      "Number of train buckets:  30824\n",
      "Number of test buckets:  3425\n",
      "Type of train_dataset [<torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal object at 0x000002BF829DF970>]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 294.00 MiB (GPU 0; 6.00 GiB total capacity; 5.08 GiB already allocated; 0 bytes free; 5.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m600\u001b[39m\n\u001b[0;32m     12\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m---> 13\u001b[0m train_dataset, test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#edge_index = get_adjacent_matrix(DEVICE)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\jupyter\\learn\\dataset\\METRLADataset.py:32\u001b[0m, in \u001b[0;36mget_METRLADataset\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m     30\u001b[0m train_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(train_dataset\u001b[38;5;241m.\u001b[39mfeatures)  \u001b[38;5;66;03m# (27399, 207, 2, 12)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m train_target \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(train_dataset\u001b[38;5;241m.\u001b[39mtargets)  \u001b[38;5;66;03m# (27399, 207, 12)\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m train_x_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# (B, N, F, T)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m train_target_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(train_target)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mFloatTensor)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# (B, N, T)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m train_dataset_new \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mTensorDataset(train_x_tensor, train_target_tensor)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 294.00 MiB (GPU 0; 6.00 GiB total capacity; 5.08 GiB already allocated; 0 bytes free; 5.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch.nn\n",
    "from trainer.STTN_train import make_model as make_model\n",
    "from trainer.STTN_train import train as train\n",
    "from dataset.METRLADataset import get_METRLADataset as get_dataset\n",
    "from dataset.METRLADataset import get_METRLA_2Dadjacent_matrix as get_adjacent_matrix\n",
    "\n",
    "DEVICE = torch.device('cuda')\n",
    "adj = get_adjacent_matrix(DEVICE)\n",
    "model = make_model(DEVICE,adj)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
    "batch_size = 600\n",
    "epochs = 20\n",
    "train_dataset, test_dataset = get_dataset(DEVICE)\n",
    "#edge_index = get_adjacent_matrix(DEVICE)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    #train(train_loader, test_loader, model, optimizer, edge_index, DEVICE)\n",
    "    train(train_loader, test_loader, model, optimizer, DEVICE)\n",
    "torch.save(model, \"lstgatgcn_pth\")\n",
    "torch.save(model.state_dict, \"lstgatgcn_w.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806b992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
